## Tokyo-Olympic-Azure-Data-Engineering-Project - 2021


Designed and implemented a fully orchestrated Azure ETL pipeline for the Tokyo Olympic dataset (see project: darshant15/Tokyo-OlympicData-Azure-Dataengineering-Project). 
Leveraged Azure Data Factory to ingest CSV files from GitHub into Azure Data Lake Storage Gen2, used Databricks (Spark) for data cleaning, deduplication, and feature engineering, and loaded transformed data into Azure Synapse Analytics for robust SQL querying and insights. The pipeline includes automated scheduling and monitoring in ADF, and all notebooks and workflows are version-controlled via GitHub."

